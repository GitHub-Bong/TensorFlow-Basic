{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 11-2: mnist cnn keras functional eager.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNlV5Bi1HOJoUx9FSjop7HK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vpAU-fLQ1bJI","executionInfo":{"status":"ok","timestamp":1612942038669,"user_tz":-540,"elapsed":2495,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["import tensorflow as tf\r\n","from tensorflow import keras\r\n","from tensorflow.keras.utils import to_categorical\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import os\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4y1-VavO1ex2","executionInfo":{"status":"ok","timestamp":1612942108707,"user_tz":-540,"elapsed":696,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["learning_rate = 0.001\r\n","training_epochs = 5\r\n","batch_size = 100\r\n","\r\n","tf.random.set_seed(777)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3pxuwV71e0R","executionInfo":{"status":"ok","timestamp":1612942053808,"user_tz":-540,"elapsed":684,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["cur_dir = os.getcwd()\r\n","ckpt_dir_name = 'checkpoints'\r\n","model_dir_name = 'minst_cnn_func'\r\n","\r\n","checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\r\n","os.makedirs(checkpoint_dir, exist_ok=True)\r\n","\r\n","checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"R88_DnXF1e5t","executionInfo":{"status":"ok","timestamp":1612942085904,"user_tz":-540,"elapsed":672,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["## MNIST Dataset #########################################################\r\n","mnist = keras.datasets.mnist\r\n","class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\r\n","##########################################################################\r\n","\r\n","## Fashion MNIST Dataset #################################################\r\n","#mnist = keras.datasets.fashion_mnist\r\n","#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n","##########################################################################"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSrU0IBV1e8o","executionInfo":{"status":"ok","timestamp":1612942110444,"user_tz":-540,"elapsed":865,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \r\n","    \r\n","train_images = train_images.astype(np.float32) / 255.\r\n","test_images = test_images.astype(np.float32) / 255.\r\n","train_images = np.expand_dims(train_images, axis=-1)\r\n","test_images = np.expand_dims(test_images, axis=-1)\r\n","    \r\n","train_labels = to_categorical(train_labels, 10)\r\n","test_labels = to_categorical(test_labels, 10)    \r\n","    \r\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\r\n","                buffer_size=100000).batch(batch_size)\r\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoMNn7hc1e_e","executionInfo":{"status":"ok","timestamp":1612942121756,"user_tz":-540,"elapsed":441,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["def create_model():\r\n","    inputs = keras.Input(shape=(28, 28, 1))\r\n","    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(inputs)\r\n","    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv1)\r\n","    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool1)\r\n","    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv2)\r\n","    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool2)\r\n","    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv3)\r\n","    pool3_flat = keras.layers.Flatten()(pool3)\r\n","    dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)(pool3_flat)\r\n","    drop4 = keras.layers.Dropout(rate=0.4)(dense4)\r\n","    logits = keras.layers.Dense(units=10)(drop4)\r\n","    return keras.Model(inputs=inputs, outputs=logits)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgRPivYV1fCp","executionInfo":{"status":"ok","timestamp":1612942130202,"user_tz":-540,"elapsed":692,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}},"outputId":"c5978d16-5fc1-40a5-9015-5b26151fe314"},"source":["model = create_model()\r\n","model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               524544    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 619,786\n","Trainable params: 619,786\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UoCfJQQE1fFP","executionInfo":{"status":"ok","timestamp":1612942148333,"user_tz":-540,"elapsed":651,"user":{"displayName":"유진호","photoUrl":"","userId":"08916484587507536025"}}},"source":["@tf.function\r\n","def loss_fn(model, images, labels):\r\n","    logits = model(images, training=True)\r\n","    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\r\n","        y_pred=logits, y_true=labels, from_logits=True))    \r\n","    return loss"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AL1ZWzH81fH9"},"source":["@tf.function\r\n","def grad(model, images, labels):\r\n","    with tf.GradientTape() as tape:\r\n","        loss = loss_fn(model, images, labels)\r\n","    return tape.gradient(loss, model.variables)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYhz4I5-1fK_"},"source":["@tf.function\r\n","def evaluate(model, images, labels):\r\n","    logits = model(images, training=False)\r\n","    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\r\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"urIxz0zc1fN1"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ty9j0_5U2F11"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5lTIh-P2F6l"},"source":["@tf.function\r\n","def train(model, images, labels):\r\n","    grads = grad(model, images, labels)\r\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmzYRun82F8D"},"source":["# train my model\r\n","print('Learning started. It takes sometime.')\r\n","for epoch in range(training_epochs):\r\n","    avg_loss = 0.\r\n","    avg_train_acc = 0.\r\n","    avg_test_acc = 0.\r\n","    train_step = 0\r\n","    test_step = 0\r\n","    \r\n","    for images, labels in train_dataset:\r\n","        train(model, images, labels)\r\n","        #grads = grad(model, images, labels)                \r\n","        #optimizer.apply_gradients(zip(grads, model.variables))\r\n","        loss = loss_fn(model, images, labels)\r\n","        acc = evaluate(model, images, labels)\r\n","        avg_loss = avg_loss + loss\r\n","        avg_train_acc = avg_train_acc + acc\r\n","        train_step += 1\r\n","    avg_loss = avg_loss / train_step\r\n","    avg_train_acc = avg_train_acc / train_step\r\n","    \r\n","    for images, labels in test_dataset:        \r\n","        acc = evaluate(model, images, labels)        \r\n","        avg_test_acc = avg_test_acc + acc\r\n","        test_step += 1    \r\n","    avg_test_acc = avg_test_acc / test_step    \r\n","\r\n","    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \r\n","          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \r\n","          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\r\n","    \r\n","    checkpoint.save(file_prefix=checkpoint_prefix)\r\n","\r\n","print('Learning Finished!')"],"execution_count":null,"outputs":[]}]}